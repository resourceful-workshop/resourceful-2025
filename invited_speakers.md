---
layout: default
title: RESOURCEFUL-2025
---
{% if jekyll.environment  == "production" %}
        {% assign basepath = "." %}
        {%else%}
        {% assign basepath = "" %}
        {% endif %}


<div>
    <div class="iblock headshot-invited-speaker">
        <img src="{{basepath}}/images/speakers/Megyesi.jpg" class="headshot">
                <a href="https://www.su.se/english/profiles/beba5639-1.468162?open-collapse-boxes=body-research" class="headshotaffiliation"> Beáta Megyesi </a>
        <div class="headshotname"> Stockholm University </div>
    </div>
</div>

<br>

**Bio**
Beáta Megyesi is a Professor of Computational Linguistics at Stockholm University. She completed her studies at Stockholm University and earned her doctorate from the Royal Institute of Technology in 2002. In 2003, she joined Uppsala University, where she advanced from assistant professor to full professor by 2021. Over the course of her academic career, she has published more than 100 publications and secured nearly 100 million SEK in external funding. She has served as Chair of the Swedish Research Council's Linguistics Review Panel, President of the Northern European Association for Language Technology, and Head of the Department of Linguistics and Philology at Uppsala University. She is currently the Principal Investigator of the DECRYPT project (2018–2025) on historical cryptology financed by the Swedish research Council and leads the DESCRYPT: Echoes of History Analysis and Decipherment of Historical Writings program funded by Riksbankens Jubileumsfond (2025–2032).

**Talk: Unlocking Hidden Histories: AI and Expert Collaboration in Deciphering Rare Scripts**

Manuscripts written in rare or unknown scripts represent a largely untapped reservoir of historical and cultural knowledge, yet their study is frequently sidelined due to the multifaceted challenges they present. These texts, characterized by unique linguistic structures and diverse symbol sets, demand an interdisciplinary approach that spans linguistic analysis, paleography, cryptanalysis, and cultural studies. While recent advancements in artificial intelligence have introduced promising tools for automating tasks such as identification and transcription, the nuanced interpretation and verification of these manuscripts remain firmly in the realm of human expertise. In this talk, I will explore the inherent complexities of working with rare scripts, discuss the current state of automation in manuscript analysis, and argue for the development of hybrid systems that combine AI efficiency with expert intervention. By enabling minimal corrective inputs and adapting models to various handwriting styles and script idiosyncrasies, such systems have the potential to bridge the gap between computational capabilities and the specialized domain knowledge required for meaningful historical interpretation.




<!--
<div>
    <div class="iblock headshot-invited-speaker">
        <img src="{{basepath}}/images/speakers/Tiedemann.jpg" class="headshot">
        <a href="https://blogs.helsinki.fi/tiedeman/" class="headshotaffiliation"> Jörg Tiedemann </a>
        <div class="headshotname"> University of Helsinki </div>
    </div>
</div>

**Bio**

Jörg Tiedemann is professor of language technology at the Department of Digital Humanities at the University of Helsinki. He received his PhD in computational linguistics for work on bitext alignment and machine translation from Uppsala University before moving to the University of Groningen for 5 years of post-doctoral research on question answering and information extraction. His main research interests are connected with massively multilingual data sets and data-driven natural language processing and he currently runs an ERC-funded project on representation learning and natural language understanding.

**Talk: Democratizing Machine Translation with OPUS and OPUS-MT**

The demand for translation is ever growing and this trend will not stop. Being able to access the same kind of information is a fundamental prerequisite for equality in society and translation plays a crucial role when fighting discrimination based on language barriers. Efficient tools and a better coverage of the linguistic diversity in the World are necessary to cope with the amount of material that needs to be handled. Our mission is to support the development of high quality tools for automatic and computer-assisted translation by providing open services and resources that are independent of commercial interests and profit-driven companies. Equal information access is a human right and not only a privilege for people who can pay for it. In this talk I will discuss the current state of OPUS-MT, our project on open neural machine translation and the challenges that we try to tackle with multilingual NLP, transfer learning and data augmentation. I will report about on-going work on knowledge distillation, the creation of compact models for real-time translation and our work on modularization of neural MT.


<div>
    <div class="iblock headshot-invited-speaker">
        <img src="{{basepath}}/images/speakers/Darja-Fiser.jpg" class="headshot">
        <a href="www.clarin.eu/person/darja-fiser" class="headshotaffiliation"> Darja Fišer </a>
        <div class="headshotname"> Institute of Contemporary History, Ljubljana </div>
    </div>
</div>

**Bio**

Darja Fišer is Executive Director of CLARIN. She has a background in corpus linguistics and language resource creation. She has been Associate Professor at the Faculty of Arts, University of Ljubljana, since 2019, Senior Research Fellow at the Institute of Contemporary History since 2021, and is leading the new national research programme for Digital Humanities in Slovenia. She is also serving as a member of the Scientific Advisory Board of the Austrian Centre for Digital Humanities at the Austrian Academy of Sciences, the National Interdisciplinary Research E-Infrastructure for Bulgarian Language and Cultural Heritage Resources and Technologies, and the Czech National Corpus research infrastructure of the Institute of the Czech National Corpus at Charles University.

**Talk:  The role of the CLARIN research infrastructure in the era of data-intensive language studies**

 Advances in digitization and datafication have been transformative for linguistics and other disciplines that work with language materials. This has increased the need for research infrastructures that supports the development, documentation, archiving, dissemination, reuse and citation of language resources and tools which is prerequisite for verifiable and reproducible research. In this talk I will present the recent achievements and ongoing work of the CLARIN research infrastructure which is based on the Open Science paradigm and FAIR data principles. It provides easy and sustainable access to digital language data and offers advanced tools to discover, explore, annotate, analyse, and combine such datasets, wherever they are located. This is enabled through a networked federation of centres: language data repositories, service centres, and knowledge centres with single sign-on access for all members of the academic community in all participating countries. Tools, data and metadata from different centres are interoperable so that data collections can be combined and tools from different sources can be chained to perform operations at different levels of complexity. 

-->
